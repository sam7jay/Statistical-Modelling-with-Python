{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea28fba",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "452fa215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.15568935331026412\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        bikes_available   R-squared:                       0.172\n",
      "Model:                            OLS   Adj. R-squared:                  0.160\n",
      "Method:                 Least Squares   F-statistic:                     14.07\n",
      "Date:                Wed, 07 Jun 2023   Prob (F-statistic):           1.10e-18\n",
      "Time:                        13:27:14   Log-Likelihood:                -1734.2\n",
      "No. Observations:                 552   AIC:                             3486.\n",
      "Df Residuals:                     543   BIC:                             3525.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const         2721.0765    602.025      4.520      0.000    1538.493    3903.660\n",
      "index           -0.0022      0.001     -1.643      0.101      -0.005       0.000\n",
      "latitude       -64.3195      8.814     -7.298      0.000     -81.632     -47.007\n",
      "longitude       -1.2310      4.433     -0.278      0.781      -9.939       7.477\n",
      "distance_x      -0.0444      0.009     -5.142      0.000      -0.061      -0.027\n",
      "rating          -0.6578      1.329     -0.495      0.621      -3.269       1.953\n",
      "review_count    -0.0022      0.004     -0.495      0.621      -0.011       0.007\n",
      "price           -0.2223      2.512     -0.088      0.930      -5.157       4.713\n",
      "distance_y      -0.0003      0.002     -0.217      0.828      -0.003       0.003\n",
      "==============================================================================\n",
      "Omnibus:                       85.138   Durbin-Watson:                   1.901\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              141.733\n",
      "Skew:                           0.952   Prob(JB):                     1.67e-31\n",
      "Kurtosis:                       4.593   Cond. No.                     1.83e+06\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.83e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import eli5\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to load data from an SQLite database\n",
    "def load_data(database_path, query):\n",
    "    conn = sqlite3.connect(database_path)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    df = df.drop([\"fsq_id\", \"category_id\", \"location_postcode\", \"location_region\", \"location_timezone\",\n",
    "                  'name_x', \"name_y\", \"name\", \"chains\", \"location_country\", \"location_cross_street\",\n",
    "                  \"location_formatted_address\", \"location_locality\", \"category_name\", \"category\"], axis=1)\n",
    "    \n",
    "    df.price = df.price.map({'$': 0, '$$': 1, '$$$': 2, '$$$$': 3})\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # OneHotEncode price\n",
    "    price = df.price.values.reshape(-1, 1)\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(price)\n",
    "    one_hot_encoded = encoder.transform(price).toarray()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    print(\"R-squared:\", reg.score(X_test, y_test))\n",
    "\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    model = sm.OLS(y_train, X_train).fit()\n",
    "    print(model.summary())\n",
    "\n",
    "database_path = 'G:/Data/Python Project/database.sqlite'\n",
    "query = \"SELECT * FROM merged_data\"\n",
    "\n",
    "# Load data\n",
    "df = load_data(database_path, query)\n",
    "\n",
    "# Preprocess data\n",
    "df = preprocess_data(df)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = df.drop(\"bikes_available\", axis=1)\n",
    "y = df[\"bikes_available\"]\n",
    "\n",
    "# Train and evaluate the model\n",
    "train_and_evaluate(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7e98d",
   "metadata": {},
   "source": [
    "## RESULTS: the model is not good fit because R-square is too low which show a low correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8784a",
   "metadata": {},
   "source": [
    "**Stretch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a2e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    384\n",
      "1    168\n",
      "Name: bikes_available_high, dtype: int64\n",
      "0.0    71\n",
      "1.0    71\n",
      "Name: bikes_available, dtype: int64\n",
      "AUC-ROC score: 0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Check the balance of your classes\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.bikes_available==0]\n",
    "df_minority = df[df.bikes_available==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,                     # sample with replacement\n",
    "                                 n_samples=df_majority.shape[0],   # to match majority class\n",
    "                                 random_state=123)                 # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Display new class counts\n",
    "print(df_upsampled.bikes_available.value_counts())\n",
    "\n",
    "# Define new X and y\n",
    "X_upsampled = df_upsampled.drop('bikes_available', axis=1)\n",
    "y_upsampled = df_upsampled.bikes_available\n",
    "\n",
    "# Preprocess your data differently: Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_upsampled = scaler.fit_transform(X_upsampled)\n",
    "\n",
    "# Split the data into training and testing sets again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_upsampled, y_upsampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tune your model: Use LogisticRegressionCV to find the best regularization strength\n",
    "logreg = LogisticRegressionCV(cv=5, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate your model with a different metric: AUC-ROC score\n",
    "print(\"AUC-ROC score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
